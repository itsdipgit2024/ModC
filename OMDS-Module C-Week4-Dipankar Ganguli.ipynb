{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5dd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statlog=pd.read_csv('capstone datasets/Heart Disease Statlog/Heart_disease_statlog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d413a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       270 non-null    int64  \n",
      " 1   sex       270 non-null    int64  \n",
      " 2   cp        270 non-null    int64  \n",
      " 3   trestbps  270 non-null    int64  \n",
      " 4   chol      270 non-null    int64  \n",
      " 5   fbs       270 non-null    int64  \n",
      " 6   restecg   270 non-null    int64  \n",
      " 7   thalach   270 non-null    int64  \n",
      " 8   exang     270 non-null    int64  \n",
      " 9   oldpeak   270 non-null    float64\n",
      " 10  slope     270 non-null    int64  \n",
      " 11  ca        270 non-null    int64  \n",
      " 12  thal      270 non-null    int64  \n",
      " 13  target    270 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 29.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_statlog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd37c60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.433333</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>2.174074</td>\n",
       "      <td>131.344444</td>\n",
       "      <td>249.659259</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>149.677778</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>1.05000</td>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>1.822222</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.109067</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.950090</td>\n",
       "      <td>17.861608</td>\n",
       "      <td>51.686237</td>\n",
       "      <td>0.355906</td>\n",
       "      <td>0.997891</td>\n",
       "      <td>23.165717</td>\n",
       "      <td>0.470952</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>0.614390</td>\n",
       "      <td>0.943896</td>\n",
       "      <td>0.959140</td>\n",
       "      <td>0.497827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  270.000000  270.000000  270.000000  270.000000  270.000000  270.000000   \n",
       "mean    54.433333    0.677778    2.174074  131.344444  249.659259    0.148148   \n",
       "std      9.109067    0.468195    0.950090   17.861608   51.686237    0.355906   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    2.000000  120.000000  213.000000    0.000000   \n",
       "50%     55.000000    1.000000    2.000000  130.000000  245.000000    0.000000   \n",
       "75%     61.000000    1.000000    3.000000  140.000000  280.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang    oldpeak       slope          ca  \\\n",
       "count  270.000000  270.000000  270.000000  270.00000  270.000000  270.000000   \n",
       "mean     1.022222  149.677778    0.329630    1.05000    0.585185    0.670370   \n",
       "std      0.997891   23.165717    0.470952    1.14521    0.614390    0.943896   \n",
       "min      0.000000   71.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "50%      2.000000  153.500000    0.000000    0.80000    1.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.60000    1.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.20000    2.000000    3.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  270.000000  270.000000  \n",
       "mean     1.822222    0.444444  \n",
       "std      0.959140    0.497827  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statlog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c5fcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306fefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_statlog.drop(labels='target',axis=1)\n",
    "y=df_statlog['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851806b",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a27f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_features std is [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "standard_features mean is [ 3.66784792e-16  6.57909941e-18  6.08566695e-17  5.68269711e-16\n",
      " -2.46716228e-16  4.19417587e-17  3.12507222e-17  2.63163976e-17\n",
      "  7.89491929e-17 -5.26327952e-17  9.82752974e-17 -6.57909941e-17\n",
      "  3.94745964e-17]\n"
     ]
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "X_standardized=scaler.fit_transform(X)\n",
    "print(f'standard_features std is {X_standardized.std(axis=0)}')\n",
    "print(f'standard_features mean is {X_standardized.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d50d9f",
   "metadata": {},
   "source": [
    "#### Applying Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26f3ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       150\n",
      "           1       0.85      0.80      0.82       120\n",
      "\n",
      "    accuracy                           0.85       270\n",
      "   macro avg       0.85      0.84      0.85       270\n",
      "weighted avg       0.85      0.85      0.85       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression=LogisticRegression(random_state=42)\n",
    "model=logistic_regression.fit(X_standardized,y)\n",
    "y_predict=model.predict(X_standardized)\n",
    "y_predict_proba=model.predict_proba(X_standardized)\n",
    "\n",
    "accuracy = accuracy_score(y, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece7065",
   "metadata": {},
   "source": [
    "#### Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96e7a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer=Normalizer()\n",
    "X_normalized=normalizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f31891d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75       150\n",
      "           1       0.75      0.38      0.50       120\n",
      "\n",
      "    accuracy                           0.67       270\n",
      "   macro avg       0.70      0.64      0.62       270\n",
      "weighted avg       0.69      0.67      0.64       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression=LogisticRegression(random_state=42)\n",
    "model=logistic_regression.fit(X_normalized,y)\n",
    "y_predict=model.predict(X_normalized)\n",
    "y_predict_proba=model.predict_proba(X_normalized)\n",
    "\n",
    "accuracy = accuracy_score(y, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c87597",
   "metadata": {},
   "source": [
    "#### You can see the accuracy has decreased with the normalization. So basically, normalization is typically not used for Logistic Regression. It is used for distance or direction based models such as \n",
    "\n",
    "PCA<br>\n",
    "KNN<br>\n",
    "K-Means Clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
